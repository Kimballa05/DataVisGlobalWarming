{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adad29c0",
   "metadata": {},
   "source": [
    "Alex Kimball (u1195729)  <br>\n",
    "Faisal Karim (u1418923)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb39828",
   "metadata": {},
   "source": [
    "## This project's goal is to observe the world demopgraphy and the impact of literacy rate on many aspects. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27c0129",
   "metadata": {},
   "source": [
    "### We sourced our data from OurWorldinData.org and gapminder.org. The loaded file below represent the raw data. The data set named as \"Other Data - Copy.csv\" is a amalagamation of multiple data sources from gapminder and ourworldindata. As we slowly accumulated this data set it needed to be cleaned by hand and with the help of chatGPT. As the country name in those each datasets were different It was not possible to just attach them with the help of Panda. This is how it was done:\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2de065",
   "metadata": {},
   "source": [
    "####    Step 1: Upload the new dataset in ChatGPT with the previous dataset were I want it merge. We had to use 2011 dataset as that was the latest one available for literacy rate (But for the heatmap we used the latest 2021 data). Prompt: From the newdataset.csv take the 2011 column and attach it olddataset.csv using country name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977eb5e4",
   "metadata": {},
   "source": [
    "#### Step 2: After ChatGPT gave us the new one. We had to do some correction by hand. For example some data set had USA and some had United States. So, a bit of manual clean up was required\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7bd096",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2677a4e",
   "metadata": {},
   "source": [
    "### The datasets below are our initial raw datasets. The datasets from gapminder had lots of region based data. We had to match it with our GeoJson data too. So after some digging around we were able to remove the the country that we won't be showing in our heat map. The datasets from ourworldindata.com was mainly used for the heatmap of world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6d11545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "\n",
    "pop_raw = pd.read_csv('./population-and-demography.csv')\n",
    "male_pop_raw = pd.read_csv('./Male - population-and-demography.csv')\n",
    "female_pop_raw = pd.read_csv('./female - population-and-demography.csv')\n",
    "life_expec_raw = pd.read_csv('./life expectancy - population-and-demography.csv')\n",
    "death_rate_raw = pd.read_csv('./death rate - population-and-demography.csv')\n",
    "birth_rate_raw = pd.read_csv('./birth rate - population-and-demography.csv')\n",
    "child_death_raw = pd.read_csv('./child mortality rate - population-and-demography.csv')\n",
    "other_data_raw = pd.read_csv('./Other data - Copy.csv')\n",
    "\n",
    "\n",
    "                   \n",
    "# List of non-country entries created by chat GPT \n",
    "non_countries = [\n",
    "    'Africa (UN)', 'Asia (UN)', 'Europe (UN)', 'High-income countries', 'Land-locked developing countries (LLDC)', \n",
    "    'Latin America and the Caribbean (UN)', 'Least developed countries', 'Less developed regions', \n",
    "    'Less developed regions, excluding China', 'Less developed regions, excluding least developed countries', \n",
    "    'Low-income countries', 'Lower-middle-income countries', 'More developed regions', 'Northern America (UN)',\n",
    "    'Oceania (UN)', 'Small island developing states (SIDS)', 'Upper-middle-income countries', 'World', 'Aruba', 'Barbados', 'Burundi', 'Saint Barthelemy', 'Bermuda', 'Brunei',\n",
    "    'Bonaire Sint Eustatius and Saba', \"Cote d'Ivoire\", 'Curacao', 'Falkland Islands',\n",
    "    'French Guiana', 'Guernsey', 'Guam', 'Jersey', 'Kiribati', 'Saint Martin (French part)',\n",
    "    'Northern Mariana Islands', 'Nauru', 'Niue', 'Reunion', 'Rwanda',\n",
    "    'Sint Maarten (Dutch part)', 'Tokelau', 'Turkey', 'Kosovo', 'Yemen' \n",
    "]\n",
    "\n",
    "# Filter out the non-country entries\n",
    "pop = pop_raw[~pop_raw['Country name'].isin(non_countries)]\n",
    "male_pop = male_pop_raw[~male_pop_raw['Country name'].isin(non_countries)]\n",
    "female_pop = female_pop_raw[~female_pop_raw['Country name'].isin(non_countries)]\n",
    "life_expec_raw2 = life_expec_raw[~life_expec_raw['Country name'].isin(non_countries)]\n",
    "death_rate_raw2 = death_rate_raw[~death_rate_raw['Country name'].isin(non_countries)]\n",
    "birth_rate_raw2 = birth_rate_raw [~birth_rate_raw ['Country name'].isin(non_countries)]\n",
    "child_death_raw2 = child_death_raw[~child_death_raw['Country name'].isin(non_countries)]\n",
    "other_data_raw2 = other_data_raw[~other_data_raw['Country name'].isin(non_countries)]\n",
    "\n",
    "#Filter out 'Vatican' from some files\n",
    "death_rate = death_rate_raw2[death_rate_raw2['Country name'] != 'Vatican']\n",
    "birth_rate = birth_rate_raw2[birth_rate_raw2['Country name'] != 'Vatican']\n",
    "child_death = child_death_raw2[child_death_raw2['Country name'] != 'Vatican']\n",
    "life_expec = life_expec_raw2[life_expec_raw2['Country name'] != 'Vatican']\n",
    "other_data = other_data_raw2[other_data_raw2['Country name'] != 'Vatican']\n",
    "\n",
    "# other_data.to_csv('./other_data.csv', index=False)\n",
    "# child_death.to_csv('./child_death.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2e8cc0",
   "metadata": {},
   "source": [
    "### In the next cell We only kept the column that I will use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89bf267",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pop[['Country name', 'Year', 'Population']]\n",
    "male_pop = male_pop[['Country name', 'Year', 'Male population']]\n",
    "female_pop = female_pop[['Country name', 'Year', 'Female population']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e689b5",
   "metadata": {},
   "source": [
    "### All the data we had didn't have any ISO3 code with them which we will use to make a link with our worl.json file. So we used chatGPT to create the ISO3 for every countyr. The prompt was \"Here is the name of the countires. Now use your knowledge to give me the ISO3 and ISO2 for the countires and give me the list in a CSV file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da9c1522",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = pd.read_csv('./Country_with_ISO_Codes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196c9491",
   "metadata": {},
   "source": [
    "### Creating a new dataset combining all the datasets from ourworldindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a504cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'pop': pop,\n",
    "    'male_pop': male_pop,\n",
    "    'female_pop': female_pop,\n",
    "    'death_rate': death_rate,\n",
    "    'birth_rate': birth_rate,\n",
    "    'child_death': child_death\n",
    "}\n",
    "\n",
    "\n",
    "columns_to_take = [\n",
    "    ['Country name', 'Year', 'Population'],\n",
    "    ['Country name', 'Year', 'Male population'],\n",
    "    ['Country name', 'Year', 'Female population'],\n",
    "    ['Country name', 'Year', 'Death rate'],\n",
    "    ['Country name', 'Year', 'Birth rate'],\n",
    "    ['Country name', 'Year', 'Child mortality rate']\n",
    "]\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over the datasets and columns\n",
    "for dataset_name, columns in zip(dataframes.keys(), columns_to_take):\n",
    "    df = dataframes[dataset_name][columns]\n",
    "    if final_df.empty:\n",
    "        final_df = df\n",
    "    else:\n",
    "        final_df = final_df.merge(df, on=['Country name', 'Year'], how='inner')\n",
    "\n",
    "\n",
    "#Merging data with ISO        \n",
    "final = final_df.merge(iso, on='Country name', how='left')\n",
    "\n",
    "# final.to_csv('./final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc61ed",
   "metadata": {},
   "source": [
    "### Merging data for heatmap with GEO JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8a9b654",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Load the GeoJSON data\n",
    "world_geo = gpd.read_file('./world.json')\n",
    "\n",
    "# Filter the population data for the year 2021\n",
    "final_2021 = final[final['Year'] == 2021]\n",
    "\n",
    "# Merge the population data with geographical data using ISO3 codes\n",
    "merged_data = world_geo.merge(final_2021, left_on='id', right_on='ISO3')\n",
    "\n",
    "# Applying a logarithmic scale to the population data\n",
    "merged_data['Log_Population'] = np.log1p(merged_data['Population'])\n",
    "\n",
    "# Convert the merged GeoDataFrame to a GeoJSON format\n",
    "geojson_data = json.loads(merged_data.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1ddb16",
   "metadata": {},
   "source": [
    "### Later on, for each plot data sets were a bit handeled in the explanatory notebook. In some cases we removed some countries like Australia, Equatorial Guinea, Papua New Guinea to tackle the outliers. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
